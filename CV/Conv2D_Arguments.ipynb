{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Conv2D - Arguments (Interactive).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Conv2D: Ð˜ÑÑÐ»ÐµÐ´Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð°Ñ€Ð³ÑƒÐ¼ÐµÐ½Ñ‚Ð¾Ð² (Ñ Ð¸Ð½Ñ‚ÐµÑ€Ð°ÐºÑ‚Ð¸Ð²Ð½Ñ‹Ð¼ Playground)\n",
        "**ðŸ‡·ðŸ‡º (RU)**: Ð’ ÑÑ‚Ð¾Ð¼ Ð½Ð¾ÑƒÑ‚Ð±ÑƒÐºÐµ Ð¼Ñ‹ Ð¸ÑÑÐ»ÐµÐ´ÑƒÐµÐ¼, ÐºÐ°Ðº Ñ€Ð°Ð·Ð»Ð¸Ñ‡Ð½Ñ‹Ðµ Ð°Ñ€Ð³ÑƒÐ¼ÐµÐ½Ñ‚Ñ‹ ÑÐ»Ð¾Ñ `Conv2D` Ð² TensorFlow/Keras Ð²Ð»Ð¸ÑÑŽÑ‚ Ð½Ð° Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚ ÑÐ²ÐµÑ€Ñ‚ÐºÐ¸. Ð¡Ð½Ð°Ñ‡Ð°Ð»Ð° Ð¼Ñ‹ Ñ€Ð°ÑÑÐ¼Ð¾Ñ‚Ñ€Ð¸Ð¼ ÐºÐ°Ð¶Ð´Ñ‹Ð¹ Ð²Ð°Ð¶Ð½Ñ‹Ð¹ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€ ÑˆÐ°Ð³ Ð·Ð° ÑˆÐ°Ð³Ð¾Ð¼, Ð° Ð² ÐºÐ¾Ð½Ñ†Ðµ Ð²Ñ‹ Ð½Ð°Ð¹Ð´ÐµÑ‚Ðµ Ð¸Ð½Ñ‚ÐµÑ€Ð°ÐºÑ‚Ð¸Ð²Ð½ÑƒÑŽ Ð¿ÐµÑÐ¾Ñ‡Ð½Ð¸Ñ†Ñƒ, Ð³Ð´Ðµ ÑÐ¼Ð¾Ð¶ÐµÑ‚Ðµ Ð¿Ð¾ÑÐºÑÐ¿ÐµÑ€Ð¸Ð¼ÐµÐ½Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ ÑÐ°Ð¼Ð¾ÑÑ‚Ð¾ÑÑ‚ÐµÐ»ÑŒÐ½Ð¾.\n",
        "\n",
        "---\n",
        "\n",
        "**ðŸ‡¬ðŸ‡§ (EN)**: In this notebook, we'll explore how different arguments of the `Conv2D` layer in TensorFlow/Keras affect the convolution output. First, we will look at each important parameter step-by-step, and at the end, you will find an interactive sandbox where you can experiment on your own."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from typing import Tuple, Optional\n",
        "import ipywidgets as widgets\n",
        "from ipywidgets import interact"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "input_image = np.arange(1, 26).reshape((5, 5))\n",
        "print(\"ÐÐ°ÑˆÐ° 'ÐºÐ°Ñ€Ñ‚Ð¸Ð½ÐºÐ°' (Ð²Ñ…Ð¾Ð´Ð½Ñ‹Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ):\\n\")\n",
        "print(input_image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ð’ÑÐ¿Ð¾Ð¼Ð¾Ð³Ð°Ñ‚ÐµÐ»ÑŒÐ½Ð°Ñ Ñ„ÑƒÐ½ÐºÑ†Ð¸Ñ Ð´Ð»Ñ Ð²Ð¸Ð·ÑƒÐ°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ð¸\n",
        "\n",
        "**ðŸ‡·ðŸ‡º (RU)**: Ð§Ñ‚Ð¾Ð±Ñ‹ Ð½Ðµ Ð¿Ð¾Ð²Ñ‚Ð¾Ñ€ÑÑ‚ÑŒ ÐºÐ¾Ð´, Ð¼Ñ‹ ÑÐ¾Ð·Ð´Ð°Ð´Ð¸Ð¼ Ð¾Ð´Ð½Ñƒ Ñ„ÑƒÐ½ÐºÑ†Ð¸ÑŽ, ÐºÐ¾Ñ‚Ð¾Ñ€Ð°Ñ Ð±ÑƒÐ´ÐµÑ‚ Ð¿Ñ€Ð¾Ð²Ð¾Ð´Ð¸Ñ‚ÑŒ ÑÐºÑÐ¿ÐµÑ€Ð¸Ð¼ÐµÐ½Ñ‚: ÑÐ¾Ð·Ð´Ð°Ð²Ð°Ñ‚ÑŒ Ð¼Ð¾Ð´ÐµÐ»ÑŒ, Ð¿Ñ€Ð¸Ð¼ÐµÐ½ÑÑ‚ÑŒ ÑÐ²ÐµÑ€Ñ‚ÐºÑƒ Ð¸ Ñ€Ð¸ÑÐ¾Ð²Ð°Ñ‚ÑŒ Ñ‚Ñ€Ð¸ ÐºÐ°Ñ€Ñ‚Ð¸Ð½ÐºÐ¸: **Ð²Ñ…Ð¾Ð´Ð½Ð¾Ðµ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ**, **ÑÐ´Ñ€Ð¾ ÑÐ²ÐµÑ€Ñ‚ÐºÐ¸** Ð¸ **Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚ (ÐºÐ°Ñ€Ñ‚Ñƒ Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¾Ð²)**.\n",
        "\n",
        "---\n",
        "\n",
        "**ðŸ‡¬ðŸ‡§ (EN)**: To avoid repeating code, we will create a single function to run the experiment: it will create a model, apply the convolution, and draw three images: the **input image**, the **convolution kernel**, and the **result (feature map)**."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def run_convolution_experiment(\n",
        "    input_data: np.ndarray,\n",
        "    kernel_size: Tuple[int, int] = (3, 3),\n",
        "    strides: Tuple[int, int] = (1, 1),\n",
        "    padding: str = \"valid\",\n",
        "    dilation_rate: Tuple[int, int] = (1, 1),\n",
        "    custom_kernel: Optional[np.ndarray] = None,\n",
        "):\n",
        "    \"\"\"ÐŸÑ€Ð¾Ð²Ð¾Ð´Ð¸Ñ‚ Ð¾Ð´Ð¸Ð½ ÑÐºÑÐ¿ÐµÑ€Ð¸Ð¼ÐµÐ½Ñ‚ ÑÐ¾ ÑÐ²ÐµÑ€Ñ‚ÐºÐ¾Ð¹ Ð¸ Ð²Ð¸Ð·ÑƒÐ°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐµÑ‚ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚.\"\"\"\n",
        "    tf.keras.backend.clear_session()\n",
        "    input_shape = input_data.shape\n",
        "\n",
        "    if len(input_shape) == 2:\n",
        "        input_data_ch = np.expand_dims(input_data, axis=-1)\n",
        "    else:\n",
        "        input_data_ch = input_data\n",
        "    \n",
        "    input_data_batch = np.expand_dims(input_data_ch, axis=0)\n",
        "\n",
        "    model = Sequential()\n",
        "    conv_layer = Conv2D(\n",
        "        filters=1,\n",
        "        kernel_size=kernel_size,\n",
        "        strides=strides,\n",
        "        padding=padding,\n",
        "        dilation_rate=dilation_rate,\n",
        "        use_bias=False,\n",
        "        input_shape=input_data_ch.shape,\n",
        "    )\n",
        "    model.add(conv_layer)\n",
        "\n",
        "    if custom_kernel is not None:\n",
        "        keras_kernel = np.reshape(custom_kernel, (*kernel_size, 1, 1))\n",
        "        model.set_weights([keras_kernel])\n",
        "\n",
        "    output_data = model.predict(input_data_batch, verbose=0)\n",
        "\n",
        "    fig, axs = plt.subplots(1, 3, figsize=(12, 4))\n",
        "    fig.suptitle(f'Kernel: {kernel_size}, Strides: {strides}, Padding: \"{padding}\", Dilation: {dilation_rate}', fontsize=14)\n",
        "\n",
        "    ax1 = axs[0]\n",
        "    im1 = ax1.imshow(input_data, cmap=\"viridis\", interpolation=\"nearest\")\n",
        "    ax1.set_title(f\"Input\\nShape: {input_data.shape}\")\n",
        "    fig.colorbar(im1, ax=ax1)\n",
        "\n",
        "    kernel_weights = model.get_weights()[0]\n",
        "    if len(kernel_weights.shape) == 4 and kernel_weights.shape[2] == 1 and kernel_weights.shape[3] == 1:\n",
        "        kernel_to_show = kernel_weights[:, :, 0, 0]\n",
        "    else:\n",
        "        kernel_to_show = kernel_weights.squeeze()\n",
        "\n",
        "    ax2 = axs[1]\n",
        "    im2 = ax2.imshow(kernel_to_show, cmap=\"inferno\", interpolation=\"nearest\")\n",
        "    ax2.set_title(f\"Kernel\\nShape: {kernel_to_show.shape}\")\n",
        "    fig.colorbar(im2, ax=ax2)\n",
        "\n",
        "    output_squeezed = output_data.squeeze()\n",
        "    ax3 = axs[2]\n",
        "    if output_squeezed.shape == ():\n",
        "        output_to_show = np.array([[output_squeezed]])\n",
        "    else:\n",
        "        output_to_show = output_squeezed\n",
        "    im3 = ax3.imshow(output_to_show, cmap=\"viridis\", interpolation=\"nearest\")\n",
        "    ax3.set_title(f\"Output\\nShape: {output_squeezed.shape}\")\n",
        "    fig.colorbar(im3, ax=ax3)\n",
        "\n",
        "    for ax in axs:\n",
        "        ax.grid(which='both', color='white', linestyle='-', linewidth=0.5)\n",
        "\n",
        "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ð§Ð°ÑÑ‚ÑŒ 1: ÐŸÐ¾ÑˆÐ°Ð³Ð¾Ð²Ð¾Ðµ Ð¸ÑÑÐ»ÐµÐ´Ð¾Ð²Ð°Ð½Ð¸Ðµ\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### `kernel_size`\n",
        "**ðŸ‡·ðŸ‡º (RU)**: `kernel_size` â€” ÑÑ‚Ð¾ Ñ€Ð°Ð·Ð¼ÐµÑ€ Â«Ð¾ÐºÐ½Ð°Â», ÐºÐ¾Ñ‚Ð¾Ñ€Ð¾Ðµ ÑÐºÐ¾Ð»ÑŒÐ·Ð¸Ñ‚ Ð¿Ð¾ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸ÑŽ. Ð”Ð°Ð²Ð°Ð¹Ñ‚Ðµ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ ÑÐ´Ñ€Ð¾ 3x3, Ð·Ð°Ð¿Ð¾Ð»Ð½ÐµÐ½Ð½Ð¾Ðµ ÐµÐ´Ð¸Ð½Ð¸Ñ†Ð°Ð¼Ð¸. ÐšÐ°Ð¶Ð´Ð¾Ðµ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ðµ Ð² Ð¸Ñ‚Ð¾Ð³Ð¾Ð²Ð¾Ð¹ ÐºÐ°Ñ€Ñ‚Ðµ Ð±ÑƒÐ´ÐµÑ‚ ÑÑƒÐ¼Ð¼Ð¾Ð¹ Ð²ÑÐµÑ… Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ð¹ Ð² Ð¾ÐºÐ½Ðµ 3x3.\n",
        "\n",
        "**ðŸ‡¬ðŸ‡§ (EN)**: `kernel_size` is the size of the \"window\" that slides over the image. Let's use a 3x3 kernel filled with ones. Each value in the resulting feature map will be the sum of all values in the 3x3 window."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kernel_3x3 = np.ones((3, 3))\n",
        "run_convolution_experiment(input_image, kernel_size=(3, 3), custom_kernel=kernel_3x3)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### `strides`\n",
        "**ðŸ‡·ðŸ‡º (RU)**: `strides` â€” ÑÑ‚Ð¾ ÑˆÐ°Ð³, Ñ ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ð¼ ÑÐ´Ñ€Ð¾ Ð´Ð²Ð¸Ð³Ð°ÐµÑ‚ÑÑ Ð¿Ð¾ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸ÑŽ. Ð¨Ð°Ð³ (2, 2) Ð¾Ð·Ð½Ð°Ñ‡Ð°ÐµÑ‚, Ñ‡Ñ‚Ð¾ ÑÐ´Ñ€Ð¾ Ð±ÑƒÐ´ÐµÑ‚ Ð¿ÐµÑ€ÐµÐ¿Ñ€Ñ‹Ð³Ð¸Ð²Ð°Ñ‚ÑŒ Ñ‡ÐµÑ€ÐµÐ· Ð¾Ð´Ð¸Ð½ Ð¿Ð¸ÐºÑÐµÐ»ÑŒ. ÐŸÐ¾ÑÐ¼Ð¾Ñ‚Ñ€Ð¸Ñ‚Ðµ, ÐºÐ°Ðº ÑÑ‚Ð¾ ÑƒÐ¼ÐµÐ½ÑŒÑˆÐ°ÐµÑ‚ Ñ€Ð°Ð·Ð¼ÐµÑ€ Ð¸Ñ‚Ð¾Ð³Ð¾Ð²Ð¾Ð¹ ÐºÐ°Ñ€Ñ‚Ñ‹ Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¾Ð².\n",
        "\n",
        "**ðŸ‡¬ðŸ‡§ (EN)**: `strides` is the step size with which the kernel moves across the image. A stride of (2, 2) means the kernel will skip over one pixel at a time. Notice how this reduces the size of the final feature map."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_convolution_experiment(input_image, kernel_size=(3, 3), strides=(2, 2), custom_kernel=kernel_3x3)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### `padding`\n",
        "**ðŸ‡·ðŸ‡º (RU)**: `padding` Ð´Ð¾Ð±Ð°Ð²Ð»ÑÐµÑ‚ Â«Ñ€Ð°Ð¼ÐºÑƒÂ» Ð¸Ð· Ð½ÑƒÐ»ÐµÐ¹ Ð²Ð¾ÐºÑ€ÑƒÐ³ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ. Ð•ÑÐ»Ð¸ `padding='same'`, Ñ€Ð°Ð¼ÐºÐ° Ð±ÑƒÐ´ÐµÑ‚ Ñ‚Ð°ÐºÐ¾Ð³Ð¾ Ñ€Ð°Ð·Ð¼ÐµÑ€Ð°, Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ð¸Ñ‚Ð¾Ð³Ð¾Ð²Ð°Ñ ÐºÐ°Ñ€Ñ‚Ð° Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¾Ð² Ð±Ñ‹Ð»Ð° Ñ‚Ð¾Ð³Ð¾ Ð¶Ðµ Ñ€Ð°Ð·Ð¼ÐµÑ€Ð°, Ñ‡Ñ‚Ð¾ Ð¸ Ð²Ñ…Ð¾Ð´Ð½Ð°Ñ (Ð¿Ñ€Ð¸ ÑˆÐ°Ð³Ðµ 1). Ð­Ñ‚Ð¾ Ð¿Ð¾Ð»ÐµÐ·Ð½Ð¾, Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ð½Ðµ Ñ‚ÐµÑ€ÑÑ‚ÑŒ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÑŽ Ð¿Ð¾ ÐºÑ€Ð°ÑÐ¼.\n",
        "\n",
        "**ðŸ‡¬ðŸ‡§ (EN)**: `padding` adds a \"border\" of zeros around the image. If `padding='same'`, the border will be sized so that the output feature map is the same size as the input (with a stride of 1). This is useful for not losing information at the edges."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_convolution_experiment(input_image, kernel_size=(3, 3), padding='same', custom_kernel=kernel_3x3)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### `dilation_rate`\n",
        "**ðŸ‡·ðŸ‡º (RU)**: `dilation_rate` â€” ÑÑ‚Ð¾ Â«Ñ€Ð°Ð·Ñ€ÐµÐ¶ÐµÐ½Ð¸ÐµÂ» ÑÐ´Ñ€Ð°. Ð—Ð½Ð°Ñ‡ÐµÐ½Ð¸Ðµ (2, 2) Ð¾Ð·Ð½Ð°Ñ‡Ð°ÐµÑ‚, Ñ‡Ñ‚Ð¾ Ð¼ÐµÐ¶Ð´Ñƒ ÑÐ»ÐµÐ¼ÐµÐ½Ñ‚Ð°Ð¼Ð¸ ÑÐ´Ñ€Ð° Ð±ÑƒÐ´ÐµÑ‚ Ð¾Ð´Ð¸Ð½ Ð¿ÑƒÑÑ‚Ð¾Ð¹ Ð¿Ð¸ÐºÑÐµÐ»ÑŒ. Ð­Ñ‚Ð¾ Ð¿Ð¾Ð·Ð²Ð¾Ð»ÑÐµÑ‚ ÑÐ´Ñ€Ñƒ Â«Ð²Ð¸Ð´ÐµÑ‚ÑŒÂ» Ð±Ð¾Ð»ÑŒÑˆÑƒÑŽ Ð¾Ð±Ð»Ð°ÑÑ‚ÑŒ, Ð½Ðµ ÑƒÐ²ÐµÐ»Ð¸Ñ‡Ð¸Ð²Ð°Ñ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ð¾Ð².\n",
        "\n",
        "**ðŸ‡¬ðŸ‡§ (EN)**: `dilation_rate` refers to the \"sparseness\" of the kernel. A value of (2, 2) means there will be one empty pixel between the elements of the kernel. This allows the kernel to \"see\" a larger area without increasing the number of parameters."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_convolution_experiment(input_image, kernel_size=(3, 3), dilation_rate=(2, 2), custom_kernel=kernel_3x3)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ð§Ð°ÑÑ‚ÑŒ 2: Ð˜Ð½Ñ‚ÐµÑ€Ð°ÐºÑ‚Ð¸Ð²Ð½Ñ‹Ð¹ Playground\n",
        "---\n",
        "**ðŸ‡·ðŸ‡º (RU)**: Ð¢ÐµÐ¿ÐµÑ€ÑŒ Ð²Ð°ÑˆÐ° Ð¾Ñ‡ÐµÑ€ÐµÐ´ÑŒ! Ð”Ð²Ð¸Ð³Ð°Ð¹Ñ‚Ðµ Ð¿Ð¾Ð»Ð·ÑƒÐ½ÐºÐ¸ Ð¸ Ð²Ñ‹Ð±Ð¸Ñ€Ð°Ð¹Ñ‚Ðµ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ñ Ð¸Ð· ÑÐ¿Ð¸ÑÐºÐ¾Ð², Ñ‡Ñ‚Ð¾Ð±Ñ‹ ÑƒÐ²Ð¸Ð´ÐµÑ‚ÑŒ, ÐºÐ°Ðº Ð¼ÐµÐ½ÑÐµÑ‚ÑÑ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚ ÑÐ²ÐµÑ€Ñ‚ÐºÐ¸.\n",
        "\n",
        "**ðŸ‡¬ðŸ‡§ (EN)**: Now it's your turn! Move the sliders and select values from the dropdowns to see how the convolution output changes."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@interact(\n",
        "    kernel_size_h=widgets.IntSlider(min=1, max=5, step=2, value=3, description='Kernel Height:'),\n",
        "    kernel_size_w=widgets.IntSlider(min=1, max=5, step=2, value=3, description='Kernel Width:'),\n",
        "    stride_h=widgets.IntSlider(min=1, max=5, step=1, value=1, description='Stride Height:'),\n",
        "    stride_w=widgets.IntSlider(min=1, max=5, step=1, value=1, description='Stride Width:'),\n",
        "    padding=widgets.Dropdown(options=['valid', 'same'], value='valid', description='Padding:'),\n",
        "    dilation_h=widgets.IntSlider(min=1, max=3, step=1, value=1, description='Dilation Height:'),\n",
        "    dilation_w=widgets.IntSlider(min=1, max=3, step=1, value=1, description='Dilation Width:')\n",
        ")\n",
        "def interactive_convolution_visualizer(kernel_size_h, kernel_size_w, stride_h, stride_w, padding, dilation_h, dilation_w):\n",
        "    \"\"\"A wrapper function to connect widgets to our experiment function.\"\"\"\n",
        "    if padding == 'valid':\n",
        "        if kernel_size_h > input_image.shape[0] or kernel_size_w > input_image.shape[1]:\n",
        "            print(\"Error: Kernel size cannot be larger than the input image with 'valid' padding.\")\n",
        "            return\n",
        "            \n",
        "    custom_kernel = np.ones((kernel_size_h, kernel_size_w))\n",
        "    \n",
        "    run_convolution_experiment(\n",
        "        input_image,\n",
        "        kernel_size=(kernel_size_h, kernel_size_w),\n",
        "        strides=(stride_h, stride_w),\n",
        "        padding=padding,\n",
        "        dilation_rate=(dilation_h, dilation_w),\n",
        "        custom_kernel=custom_kernel\n",
        "    )"
      ]
    }
  ]
}
