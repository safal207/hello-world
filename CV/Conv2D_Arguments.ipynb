{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Conv2D - Arguments (Interactive).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Conv2D: –ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ (—Å –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–º Playground)\n",
        "**üá∑üá∫ (RU)**: –í —ç—Ç–æ–º –Ω–æ—É—Ç–±—É–∫–µ –º—ã –∏—Å—Å–ª–µ–¥—É–µ–º, –∫–∞–∫ —Ä–∞–∑–ª–∏—á–Ω—ã–µ –∞—Ä–≥—É–º–µ–Ω—Ç—ã —Å–ª–æ—è `Conv2D` –≤ TensorFlow/Keras –≤–ª–∏—è—é—Ç –Ω–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å–≤–µ—Ä—Ç–∫–∏. –°–Ω–∞—á–∞–ª–∞ –º—ã —Ä–∞—Å—Å–º–æ—Ç—Ä–∏–º –∫–∞–∂–¥—ã–π –≤–∞–∂–Ω—ã–π –ø–∞—Ä–∞–º–µ—Ç—Ä —à–∞–≥ –∑–∞ —à–∞–≥–æ–º, –∞ –≤ –∫–æ–Ω—Ü–µ –≤—ã –Ω–∞–π–¥–µ—Ç–µ –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—É—é –ø–µ—Å–æ—á–Ω–∏—Ü—É, –≥–¥–µ —Å–º–æ–∂–µ—Ç–µ –ø–æ—ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å —Å–∞–º–æ—Å—Ç–æ—è—Ç–µ–ª—å–Ω–æ.\n",
        "\n",
        "---\n",
        "\n",
        "**üá¨üáß (EN)**: In this notebook, we'll explore how different arguments of the `Conv2D` layer in TensorFlow/Keras affect the convolution output. First, we will look at each important parameter step-by-step, and at the end, you will find an interactive sandbox where you can experiment on your own."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from typing import Tuple, Optional\n",
        "import ipywidgets as widgets\n",
        "from ipywidgets import interact"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "input_image = np.arange(1, 26).reshape((5, 5))\n",
        "print(\"–ù–∞—à–∞ '–∫–∞—Ä—Ç–∏–Ω–∫–∞' (–≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ):\\n\")\n",
        "print(input_image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏\n",
        "\n",
        "**üá∑üá∫ (RU)**: –ß—Ç–æ–±—ã –Ω–µ –ø–æ–≤—Ç–æ—Ä—è—Ç—å –∫–æ–¥, –º—ã —Å–æ–∑–¥–∞–¥–∏–º –æ–¥–Ω—É —Ñ—É–Ω–∫—Ü–∏—é, –∫–æ—Ç–æ—Ä–∞—è –±—É–¥–µ—Ç –ø—Ä–æ–≤–æ–¥–∏—Ç—å —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç: —Å–æ–∑–¥–∞–≤–∞—Ç—å –º–æ–¥–µ–ª—å, –ø—Ä–∏–º–µ–Ω—è—Ç—å —Å–≤–µ—Ä—Ç–∫—É –∏ —Ä–∏—Å–æ–≤–∞—Ç—å —Ç—Ä–∏ –∫–∞—Ä—Ç–∏–Ω–∫–∏: **–≤—Ö–æ–¥–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ**, **—è–¥—Ä–æ —Å–≤–µ—Ä—Ç–∫–∏** –∏ **—Ä–µ–∑—É–ª—å—Ç–∞—Ç (–∫–∞—Ä—Ç—É –ø—Ä–∏–∑–Ω–∞–∫–æ–≤)**.\n",
        "\n",
        "---\n",
        "\n",
        "**üá¨üáß (EN)**: To avoid repeating code, we will create a single function to run the experiment: it will create a model, apply the convolution, and draw three images: the **input image**, the **convolution kernel**, and the **result (feature map)**."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def run_convolution_experiment(\n",
        "    input_data: np.ndarray,\n",
        "    kernel_size: Tuple[int, int] = (3, 3),\n",
        "    strides: Tuple[int, int] = (1, 1),\n",
        "    padding: str = \"valid\",\n",
        "    dilation_rate: Tuple[int, int] = (1, 1),\n",
        "    custom_kernel: Optional[np.ndarray] = None,\n",
        "):\n",
        "    \"\"\"–ü—Ä–æ–≤–æ–¥–∏—Ç –æ–¥–∏–Ω —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç —Å–æ —Å–≤–µ—Ä—Ç–∫–æ–π –∏ –≤–∏–∑—É–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç.\"\"\"\n",
        "    tf.keras.backend.clear_session()\n",
        "    input_shape = input_data.shape\n",
        "\n",
        "    if len(input_shape) == 2:\n",
        "        input_data_ch = np.expand_dims(input_data, axis=-1)\n",
        "    else:\n",
        "        input_data_ch = input_data\n",
        "    \n",
        "    input_data_batch = np.expand_dims(input_data_ch, axis=0)\n",
        "\n",
        "    model = Sequential()\n",
        "    conv_layer = Conv2D(\n",
        "        filters=1,\n",
        "        kernel_size=kernel_size,\n",
        "        strides=strides,\n",
        "        padding=padding,\n",
        "        dilation_rate=dilation_rate,\n",
        "        use_bias=False,\n",
        "        input_shape=input_data_ch.shape,\n",
        "    )\n",
        "    model.add(conv_layer)\n",
        "\n",
        "    if custom_kernel is not None:\n",
        "        keras_kernel = np.reshape(custom_kernel, (*kernel_size, 1, 1))\n",
        "        model.set_weights([keras_kernel])\n",
        "\n",
        "    output_data = model.predict(input_data_batch, verbose=0)\n",
        "\n",
        "    fig, axs = plt.subplots(1, 3, figsize=(12, 4))\n",
        "    fig.suptitle(f'Kernel: {kernel_size}, Strides: {strides}, Padding: \"{padding}\", Dilation: {dilation_rate}', fontsize=14)\n",
        "\n",
        "    ax1 = axs[0]\n",
        "    im1 = ax1.imshow(input_data, cmap=\"viridis\", interpolation=\"nearest\")\n",
        "    ax1.set_title(f\"Input\\nShape: {input_data.shape}\")\n",
        "    fig.colorbar(im1, ax=ax1)\n",
        "\n",
        "    kernel_weights = model.get_weights()[0]\n",
        "    if len(kernel_weights.shape) == 4 and kernel_weights.shape[2] == 1 and kernel_weights.shape[3] == 1:\n",
        "        kernel_to_show = kernel_weights[:, :, 0, 0]\n",
        "    else:\n",
        "        kernel_to_show = kernel_weights.squeeze()\n",
        "\n",
        "    ax2 = axs[1]\n",
        "    im2 = ax2.imshow(kernel_to_show, cmap=\"inferno\", interpolation=\"nearest\")\n",
        "    ax2.set_title(f\"Kernel\\nShape: {kernel_to_show.shape}\")\n",
        "    fig.colorbar(im2, ax=ax2)\n",
        "\n",
        "    output_squeezed = output_data.squeeze()\n",
        "    ax3 = axs[2]\n",
        "    if output_squeezed.shape == ():\n",
        "        output_to_show = np.array([[output_squeezed]])\n",
        "    else:\n",
        "        output_to_show = output_squeezed\n",
        "    im3 = ax3.imshow(output_to_show, cmap=\"viridis\", interpolation=\"nearest\")\n",
        "    ax3.set_title(f\"Output\\nShape: {output_squeezed.shape}\")\n",
        "    fig.colorbar(im3, ax=ax3)\n",
        "\n",
        "    for ax in axs:\n",
        "        ax.grid(which='both', color='white', linestyle='-', linewidth=0.5)\n",
        "\n",
        "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### –ß–∞—Å—Ç—å 1: –ü–æ—à–∞–≥–æ–≤–æ–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### `kernel_size`\n",
        "**üá∑üá∫ (RU)**: `kernel_size` ‚Äî —ç—Ç–æ —Ä–∞–∑–º–µ—Ä ¬´–æ–∫–Ω–∞¬ª, –∫–æ—Ç–æ—Ä–æ–µ —Å–∫–æ–ª—å–∑–∏—Ç –ø–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é. –î–∞–≤–∞–π—Ç–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º —è–¥—Ä–æ 3x3, –∑–∞–ø–æ–ª–Ω–µ–Ω–Ω–æ–µ –µ–¥–∏–Ω–∏—Ü–∞–º–∏. –ö–∞–∂–¥–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –≤ –∏—Ç–æ–≥–æ–≤–æ–π –∫–∞—Ä—Ç–µ –±—É–¥–µ—Ç —Å—É–º–º–æ–π –≤—Å–µ—Ö –∑–Ω–∞—á–µ–Ω–∏–π –≤ –æ–∫–Ω–µ 3x3.\n",
        "\n",
        "**üá¨üáß (EN)**: `kernel_size` is the size of the \"window\" that slides over the image. Let's use a 3x3 kernel filled with ones. Each value in the resulting feature map will be the sum of all values in the 3x3 window."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kernel_3x3 = np.ones((3, 3))\n",
        "run_convolution_experiment(input_image, kernel_size=(3, 3), custom_kernel=kernel_3x3)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### `strides`\n",
        "**üá∑üá∫ (RU)**: `strides` ‚Äî —ç—Ç–æ —à–∞–≥, —Å –∫–æ—Ç–æ—Ä—ã–º —è–¥—Ä–æ –¥–≤–∏–≥–∞–µ—Ç—Å—è –ø–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é. –®–∞–≥ (2, 2) –æ–∑–Ω–∞—á–∞–µ—Ç, —á—Ç–æ —è–¥—Ä–æ –±—É–¥–µ—Ç –ø–µ—Ä–µ–ø—Ä—ã–≥–∏–≤–∞—Ç—å —á–µ—Ä–µ–∑ –æ–¥–∏–Ω –ø–∏–∫—Å–µ–ª—å. –ü–æ—Å–º–æ—Ç—Ä–∏—Ç–µ, –∫–∞–∫ —ç—Ç–æ —É–º–µ–Ω—å—à–∞–µ—Ç —Ä–∞–∑–º–µ—Ä –∏—Ç–æ–≥–æ–≤–æ–π –∫–∞—Ä—Ç—ã –ø—Ä–∏–∑–Ω–∞–∫–æ–≤.\n",
        "\n",
        "**üá¨üáß (EN)**: `strides` is the step size with which the kernel moves across the image. A stride of (2, 2) means the kernel will skip over one pixel at a time. Notice how this reduces the size of the final feature map."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_convolution_experiment(input_image, kernel_size=(3, 3), strides=(2, 2), custom_kernel=kernel_3x3)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### `padding`\n",
        "**üá∑üá∫ (RU)**: `padding` –¥–æ–±–∞–≤–ª—è–µ—Ç ¬´—Ä–∞–º–∫—É¬ª –∏–∑ –Ω—É–ª–µ–π –≤–æ–∫—Ä—É–≥ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è. –ï—Å–ª–∏ `padding='same'`, —Ä–∞–º–∫–∞ –±—É–¥–µ—Ç —Ç–∞–∫–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞, —á—Ç–æ–±—ã –∏—Ç–æ–≥–æ–≤–∞—è –∫–∞—Ä—Ç–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –±—ã–ª–∞ —Ç–æ–≥–æ –∂–µ —Ä–∞–∑–º–µ—Ä–∞, —á—Ç–æ –∏ –≤—Ö–æ–¥–Ω–∞—è (–ø—Ä–∏ —à–∞–≥–µ 1). –≠—Ç–æ –ø–æ–ª–µ–∑–Ω–æ, —á—Ç–æ–±—ã –Ω–µ —Ç–µ—Ä—è—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –ø–æ –∫—Ä–∞—è–º.\n",
        "\n",
        "**üá¨üáß (EN)**: `padding` adds a \"border\" of zeros around the image. If `padding='same'`, the border will be sized so that the output feature map is the same size as the input (with a stride of 1). This is useful for not losing information at the edges."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_convolution_experiment(input_image, kernel_size=(3, 3), padding='same', custom_kernel=kernel_3x3)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### `dilation_rate`\n",
        "**üá∑üá∫ (RU)**: `dilation_rate` ‚Äî —ç—Ç–æ ¬´—Ä–∞–∑—Ä–µ–∂–µ–Ω–∏–µ¬ª —è–¥—Ä–∞. –ó–Ω–∞—á–µ–Ω–∏–µ (2, 2) –æ–∑–Ω–∞—á–∞–µ—Ç, —á—Ç–æ –º–µ–∂–¥—É —ç–ª–µ–º–µ–Ω—Ç–∞–º–∏ —è–¥—Ä–∞ –±—É–¥–µ—Ç –æ–¥–∏–Ω –ø—É—Å—Ç–æ–π –ø–∏–∫—Å–µ–ª—å. –≠—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç —è–¥—Ä—É ¬´–≤–∏–¥–µ—Ç—å¬ª –±–æ–ª—å—à—É—é –æ–±–ª–∞—Å—Ç—å, –Ω–µ —É–≤–µ–ª–∏—á–∏–≤–∞—è –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤.\n",
        "\n",
        "**üá¨üáß (EN)**: `dilation_rate` refers to the \"sparseness\" of the kernel. A value of (2, 2) means there will be one empty pixel between the elements of the kernel. This allows the kernel to \"see\" a larger area without increasing the number of parameters."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_convolution_experiment(input_image, kernel_size=(3, 3), dilation_rate=(2, 2), custom_kernel=kernel_3x3)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### –ß–∞—Å—Ç—å 2: –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π Playground\n",
        "---\n",
        "**üá∑üá∫ (RU)**: –¢–µ–ø–µ—Ä—å –≤–∞—à–∞ –æ—á–µ—Ä–µ–¥—å! –î–≤–∏–≥–∞–π—Ç–µ –ø–æ–ª–∑—É–Ω–∫–∏ –∏ –≤—ã–±–∏—Ä–∞–π—Ç–µ –∑–Ω–∞—á–µ–Ω–∏—è –∏–∑ —Å–ø–∏—Å–∫–æ–≤, —á—Ç–æ–±—ã —É–≤–∏–¥–µ—Ç—å, –∫–∞–∫ –º–µ–Ω—è–µ—Ç—Å—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å–≤–µ—Ä—Ç–∫–∏.\n",
        "\n",
        "**üá¨üáß (EN)**: Now it's your turn! Move the sliders and select values from the dropdowns to see how the convolution output changes."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@interact(\n",
        "    kernel_size_h=widgets.IntSlider(min=1, max=5, step=2, value=3, description='Kernel Height:'),\n",
        "    kernel_size_w=widgets.IntSlider(min=1, max=5, step=2, value=3, description='Kernel Width:'),\n",
        "    stride_h=widgets.IntSlider(min=1, max=5, step=1, value=1, description='Stride Height:'),\n",
        "    stride_w=widgets.IntSlider(min=1, max=5, step=1, value=1, description='Stride Width:'),\n",
        "    padding=widgets.Dropdown(options=['valid', 'same'], value='valid', description='Padding:'),\n",
        "    dilation_h=widgets.IntSlider(min=1, max=3, step=1, value=1, description='Dilation Height:'),\n",
        "    dilation_w=widgets.IntSlider(min=1, max=3, step=1, value=1, description='Dilation Width:')\n",
        ")\n",
        "def interactive_convolution_visualizer(kernel_size_h, kernel_size_w, stride_h, stride_w, padding, dilation_h, dilation_w):\n",
        "    \"\"\"A wrapper function to connect widgets to our experiment function.\"\"\"\n",
        "    if padding == 'valid':\n",
        "        if kernel_size_h > input_image.shape[0] or kernel_size_w > input_image.shape[1]:\n",
        "            print(\"Error: Kernel size cannot be larger than the input image with 'valid' padding.\")\n",
        "            return\n",
        "            \n",
        "    custom_kernel = np.ones((kernel_size_h, kernel_size_w))\n",
        "    \n",
        "    run_convolution_experiment(\n",
        "        input_image,\n",
        "        kernel_size=(kernel_size_h, kernel_size_w),\n",
        "        strides=(stride_h, stride_w),\n",
        "        padding=padding,\n",
        "        dilation_rate=(dilation_h, dilation_w),\n",
        "        custom_kernel=custom_kernel\n",
        "    )"
      ]
    }
  ]
}
